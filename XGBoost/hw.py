import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score, average_precision_score,
    roc_curve, precision_recall_curve
)

df = pd.read_csv("C:/Users/user/Desktop/ìˆ˜ì—…ê´€ë ¨/3í•™ë…„ 2025/1í•™ê¸°/ì¸ê³µì§€ëŠ¥/ê³¼ì œ_ì¥ì¸í™˜/XGBoost/Churn_Modelling.csv")
df.info()

# ë¶ˆí•„ìš” ì •ë³´ ì‚­ì œ
df.drop(columns=["RowNumber", "CustomerId", "Surname"], inplace=True)

# ë³€ìˆ˜ ì¸ì½”ë”©(ë¬¸ì)
df = pd.get_dummies(df, columns=["Geography", "Gender"], drop_first=True)
# xì™€ y ë¶„ë¦¬
X = df.drop("Exited", axis=1)
y = df["Exited"]
# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
# XGBoost ë¶„ë¥˜ê¸° í•™ìŠµ
model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
model.fit(X_train, y_train)

# ì˜ˆì¸¡
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]

# í‰ê°€ ì§€í‘œ ì¶œë ¥
print("ğŸ“Š Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nğŸ“„ Classification Report:\n", classification_report(y_test, y_pred))
print(f"ğŸ”¸ ROC AUC: {roc_auc_score(y_test, y_proba):.4f}")
print(f"ğŸ”¸ PR AUC: {average_precision_score(y_test, y_proba):.4f}")

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_proba)
plt.figure()
plt.plot(fpr, tpr, label=f"ROC AUC = {roc_auc_score(y_test, y_proba):.4f}")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid()
plt.show()

# PR Curve
precision, recall, _ = precision_recall_curve(y_test, y_proba)
plt.figure()
plt.plot(recall, precision, label=f"PR AUC = {average_precision_score(y_test, y_proba):.4f}")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend()
plt.grid()
plt.show()
